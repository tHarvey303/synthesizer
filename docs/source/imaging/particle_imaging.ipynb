{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "947397f6",
   "metadata": {},
   "source": [
    "# Creating Images From Galaxy Particle distributions\n",
    "\n",
    "In this example we show how to create various different types of images from stellar particles. For this purpose we utilise the parametric SFZH functionality to create fake galaxies, derive their spectra from the SPS grid and then make images using the Sythensizer Imaging submodule.\n",
    "\n",
    "## The setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46dcb7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.colors as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from unyt import yr, Myr, kpc, arcsec, nJy, Mpc\n",
    "from astropy.cosmology import Planck18 as cosmo\n",
    "from scipy import signal\n",
    "\n",
    "from synthesizer.grid import Grid\n",
    "from synthesizer.parametric.sfzh import SFH, ZH, generate_sfzh\n",
    "from synthesizer.particle.stars import sample_sfhz\n",
    "from synthesizer.particle import Stars\n",
    "from synthesizer import galaxy\n",
    "from synthesizer.particle.particles import CoordinateGenerator\n",
    "from synthesizer.filters import FilterCollection as Filters\n",
    "\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"DeJavu Serif\"\n",
    "plt.rcParams[\"font.serif\"] = [\"Times New Roman\"]\n",
    "\n",
    "# Set the seed\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aced8bcb",
   "metadata": {},
   "source": [
    "First port of call is initilaising the SPS grid. Here we use a simple test grid with limited properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869a6043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the grid\n",
    "grid_name = \"test_grid\"\n",
    "grid_dir = \"../../../tests/test_grid/\"\n",
    "grid = Grid(grid_name, grid_dir=grid_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8480b0",
   "metadata": {},
   "source": [
    "### Creating a fake galaxy\n",
    "\n",
    "With the grid in hand we need to define a star formation metallicity history from which to sample. In this toy example we use a constant SFH and metallicity history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff47e65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the metallicity history\n",
    "Z_p = {\"Z\": 0.01}\n",
    "Zh = ZH.deltaConstant(Z_p)\n",
    "\n",
    "# Define the star formation history\n",
    "sfh_p = {\"duration\": 100 * Myr}\n",
    "sfh = SFH.Constant(sfh_p)\n",
    "\n",
    "# Initialise the SFZH object\n",
    "sfzh = generate_sfzh(grid.log10age, grid.metallicity, sfh, Zh, stellar_mass=10**9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69150ac1",
   "metadata": {},
   "source": [
    "We can now sample this SFZH for individual stellar \"particles\" and create a Stars object. In a real world example the Stars can be intialised from simulation data (see a `cosmo` example to see how), here we generate random coordinates from a gaussian and simulate true smoothing lengths by making them increase with increasing radius.\n",
    "\n",
    "Note that setting attributes in this way is only necessary when sampling from a SFZH. When working with data, attributes can be passed as kwargs when intialising a Stars object. Soon this will be updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b04d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "stars_start = time.time()\n",
    "\n",
    "# Define the number of stellar particles\n",
    "n = 10000\n",
    "\n",
    "# Generate some random coordinates\n",
    "coords = CoordinateGenerator.generate_3D_gaussian(n)\n",
    "\n",
    "# Calculate the smoothing lengths from radii\n",
    "cent = np.mean(coords, axis=0)\n",
    "rs = np.sqrt(\n",
    "        (coords[:, 0] - cent[0]) ** 2\n",
    "        + (coords[:, 1] - cent[1]) ** 2\n",
    "        + (coords[:, 2] - cent[2]) ** 2\n",
    ")\n",
    "rs[rs < 0.2] = 0.6  # Set a lower bound on the \"smoothing length\"\n",
    "\n",
    "# Sample the SFZH, producing a Stars object\n",
    "# we will also pass some keyword arguments for attributes\n",
    "# we will need for imaging\n",
    "stars = sample_sfhz(sfzh, n, coordinates=coords, \n",
    "                    current_masses=np.full(n, 10**8.7 / n), \n",
    "                    smoothing_lengths=rs / 2, redshift=1,\n",
    "                    initial_mass=np.full(n, 10**6))\n",
    "\n",
    "# Compute the width of stellar distribution, we'll use this to define the FOV later\n",
    "width = (np.max(coords) - np.min(coords)) * Mpc\n",
    "\n",
    "# Add in some buffer\n",
    "width += width * 0.1\n",
    "\n",
    "print(\"Stars created, took:\", time.time() - stars_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff77b0a",
   "metadata": {},
   "source": [
    "From the Stars object we can initialise a galaxy to make an image of. The lower level imaging toolset is readily accessible to the user (see the images docs) but here we employ the helper functionality on a galaxy object to steamline the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52d3ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "galaxy_start = time.time()\n",
    "\n",
    "# Create galaxy object\n",
    "gal = galaxy(stars=stars)\n",
    "\n",
    "print(\"Galaxy created, took:\", time.time() - galaxy_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f970eff",
   "metadata": {},
   "source": [
    "### Getting the spectra\n",
    "\n",
    "To make an image we need to map the stellar particle properties onto the SPS grid defined in the `grid` object. To do this we use the galaxy's in built `generate_particle_spectra` method and create `\"total\"` SEDs with both stellar and nebular contributions. This returns an SED object containing lots of helper methods for working with spectra. \n",
    "\n",
    "Here we will use `get_fnu` to convert the rest frame SED into an observed SED which takes into account the previously set redshift stored on the `stars` object. By passing `igm=None` we assume the default `igm` contribution (`Inoue14`). This can be changed to `False` for no IGM or to another IGM model defined in `synthesizer.igm`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c67b061",
   "metadata": {},
   "outputs": [],
   "source": [
    "spectra_start = time.time()\n",
    "\n",
    "# Calculate the stellar rest frame SEDs for all particles in erg / s / Hz\n",
    "sed = gal.get_particle_spectra_incident(grid)\n",
    "\n",
    "# Calculate the observed SED in nJy\n",
    "sed.get_fnu(cosmo, stars.redshift, igm=None)\n",
    "\n",
    "print(\"Spectra created, took:\", time.time() - spectra_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804df9f6",
   "metadata": {},
   "source": [
    "### Defining filters\n",
    "\n",
    "Before making photometric images we need to define a set of filters we want images for. This can be done in a number of ways using a `FilterCollection` object. There are a number of different ways to create filters (see the filter example). Here we will get Webb filters from the SVO database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65ae407d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_start = time.time()\n",
    "\n",
    "# Define filter list\n",
    "filter_codes = [\n",
    "    \"JWST/NIRCam.F090W\",\n",
    "    \"JWST/NIRCam.F150W\",  \n",
    "    \"JWST/NIRCam.F200W\",  \n",
    "]\n",
    "\n",
    "# Set up filter object\n",
    "filters = Filters(filter_codes, new_lam=grid.lam)\n",
    "\n",
    "print(\"Filters created, took:\", time.time() - filter_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fefc73",
   "metadata": {},
   "source": [
    "## Imaging\n",
    "\n",
    "Before we make any images we need to define the resolution of our images and the FOV (or width) of the images. We do this with associated units to enable the code to internally transform all quantites to a consistent unit system. We take the units of the resolution as the unit system to which all quantities should be transformed. Here we will use kpc for all spatial quantities but this is not necessary, these units can be a mixture units with the same dimension (e.g. *physical* Mpc, kpc and pc, or arcseconds and degrees) or a mixture of angular and cartesian units (but note that angular coordinates require a redshift to be defined even when making rest frame images to enable the transformation to a consistent unit system)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01abb509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define image resolution (here we arbitrarily set it to 100 pixels along an axis)\n",
    "resolution = width / 100\n",
    "\n",
    "print(\"Image width is %.2f Mpc with %.2f Mpc resolution\" % (width.value, resolution.value))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db93b4f",
   "metadata": {},
   "source": [
    "### Stellar mass maps\n",
    "\n",
    "The base imaging classes in Synthesizer are designed to allow multiple different use cases including spectral data cubes, photometry in multiple bands, and images of arbitrary properties. Before we venture into photometry lets make a stellar mass histogram by passing the stellar masses in as `pixel_values`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8218d6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_start = time.time()\n",
    "print(resolution)\n",
    "print(stars.smoothing_lengths)\n",
    "# Get the image\n",
    "mass_hist_img = gal.make_images(\n",
    "    resolution,\n",
    "    fov=width,\n",
    "    img_type=\"hist\",\n",
    "    pixel_values=stars._current_masses, \n",
    ")\n",
    "    \n",
    "print(\"Histogram image took:\", time.time() - img_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edae37c4",
   "metadata": {},
   "source": [
    "When making a singular image from an array passed to `pixel_values` the resultant image is stored in `Image.img`. Lets plot the resulting stellar mass histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47c4981b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot what we've made\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.imshow(mass_hist_img.img)\n",
    "ax.axis(False)\n",
    "plt.show()\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd1073a",
   "metadata": {},
   "source": [
    "However, stellar particles in SPH simulations are not point sources. In fact we defined the smoothing lengths that describes each stellar particle's SPH kernel above when we made the `Stars`. If we pass `\"smoothed\"` instead of `\"hist\"` to `img_type` we can make use of these smoothing lengths and make an image of the stellar distribution correctly smoothed of the SPH kernels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82d5dcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_start = time.time()\n",
    "\n",
    "# Get the image\n",
    "mass_smooth_img = gal.make_images(\n",
    "    resolution,\n",
    "    fov=width,\n",
    "    img_type=\"smoothed\",\n",
    "    pixel_values=stars._current_masses, \n",
    ")\n",
    "    \n",
    "print(\"Smoothed image took:\", time.time() - img_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d47689",
   "metadata": {},
   "source": [
    "We also provide helper functions for making plots from the computed image arrays. In the simplest use case the user only has to state the type of image they'd like to plot: `\"standard\"` for the images we've made here, and `\"psf\"` for images with PSFs and `\"noise\"` for images including nosie, both of which we will cover shortly. The user can also optionally state the colormap to use, provide a normalisation range for the image/images and provide a function to scale the pixel values but we will ignore those here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43201780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot what we've made\n",
    "fig, ax = mass_smooth_img.plot_image(img_type=\"standard\", show=True, cmap=\"plasma\")\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e424d79",
   "metadata": {},
   "source": [
    "### Photometric imaging\n",
    "\n",
    "What we really want is observed photometric images in the filters we defined earlier. Compared to the simple mass map we now need to provide a number of extra arguments: \n",
    "\n",
    "- `sed`: The `SED` object we created earlier containing the rest frame and observed SEDs and wavelength/frequency arrays.\n",
    "- `filters`: The `FilterCollection` we defined earlier with the bands we want images in.\n",
    "- `rest_frame`: A boolean flag for whether we want the rest frame or observed photometric images. Here we will make observed images.\n",
    "- `cosmo`: The astropy.cosmology object defining the employed cosmology.\n",
    "\n",
    "Internally a spectral data cube is made first and stored in the image at `Image.ifu_obj` (the data cube array itself being stored in `Image.ifu_obj.ifu`) which the filter curves are then convolved with to produce the photometric images in each band. This process is significantly more efficient than making images using the photometry of each particle, even when only using 2 filters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1bfa17c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_start = time.time()\n",
    "\n",
    "# Get the image\n",
    "hist_img = gal.make_images(\n",
    "    resolution,\n",
    "    fov=width,\n",
    "    img_type=\"hist\",\n",
    "    sed=sed,\n",
    "    filters=filters,\n",
    "    rest_frame=False,\n",
    "    cosmo=cosmo,\n",
    ")\n",
    "\n",
    "# Get the image\n",
    "smooth_img = gal.make_images(\n",
    "    resolution,\n",
    "    fov=width,\n",
    "    img_type=\"smoothed\",\n",
    "    sed=sed,\n",
    "    filters=filters,\n",
    "    rest_frame=False,\n",
    "    cosmo=cosmo,\n",
    ")\n",
    "\n",
    "print(\"Images took:\", time.time() - img_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b2ce8c",
   "metadata": {},
   "source": [
    "When making images in multiple bands the image arrays themselves are stored in a dictionary of the form `{f.filter_code: img_array}`. Below we extract this dictionary and plot each of the images we have made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "238f5a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_imgs = hist_img.imgs\n",
    "smooth_imgs = smooth_img.imgs\n",
    "\n",
    "# Lets set up a simple normalisation across all images\n",
    "vmax = 0\n",
    "for img in hist_imgs.values():\n",
    "    up = np.percentile(img, 99.9)\n",
    "    if up > vmax:\n",
    "        vmax = up\n",
    "for img in smooth_imgs.values():\n",
    "    up = np.percentile(img, 99.9)\n",
    "    if up > vmax:\n",
    "        vmax = up\n",
    "norm = cm.Normalize(vmin=0, vmax=vmax)\n",
    "    \n",
    "# Set up plot\n",
    "fig = plt.figure(figsize=(4 * len(filters), 4 * 2))\n",
    "gs = gridspec.GridSpec(2, len(filters), hspace=0.0, wspace=0.0)\n",
    "\n",
    "# Create top row\n",
    "axes = []\n",
    "for i in range(len(filters)):\n",
    "    axes.append(fig.add_subplot(gs[0, i]))\n",
    "\n",
    "# Loop over images plotting them\n",
    "for ax, fcode in zip(axes, filter_codes):\n",
    "    ax.imshow(hist_imgs[fcode], norm=norm, cmap=\"Greys_r\")\n",
    "    ax.set_title(fcode)\n",
    "    ax.tick_params(axis='both', which='both', left=False, \n",
    "                   right=False, labelleft=False, labelright=False, \n",
    "                   bottom=False, top=False, labelbottom=False, \n",
    "                   labeltop=False)\n",
    "\n",
    "# Set y axis label on left most plot\n",
    "axes[0].set_ylabel(\"Histogram\")\n",
    "\n",
    "# Create bottom row\n",
    "axes = []\n",
    "for i in range(len(filters)):\n",
    "    axes.append(fig.add_subplot(gs[1, i]))\n",
    "\n",
    "# Loop over images plotting them\n",
    "for ax, fcode in zip(axes, filter_codes):\n",
    "    ax.imshow(smooth_imgs[fcode], norm=norm, cmap=\"Greys_r\")\n",
    "    ax.tick_params(axis='both', which='both', left=False, \n",
    "                   right=False, labelleft=False, labelright=False, \n",
    "                   bottom=False, top=False, labelbottom=False, \n",
    "                   labeltop=False)\n",
    "\n",
    "# Set y axis label on left most plot\n",
    "axes[0].set_ylabel(\"Smoothed\")\n",
    "\n",
    "# Plot the image\n",
    "plt.show()\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a548ce",
   "metadata": {},
   "source": [
    "## Including a Point Spread Function (PSF)\n",
    "\n",
    "Of course, the smoothed distribution is only part of the story. To properly model observations by a particular observatory we need to take into account the smoothing due to the PSF of the telescope. \n",
    "\n",
    "We take the PSFs as arrays stored in a dictionary of the form `{f.filter_code: psf_array}`, where each filter has its own PSF array (optionally a single array can be passed and appliec to all filters). Here we will just create a fake gaussian PSF for all filters but PSFs can be sourced however the user wishes (for Webb we recommend the _webbpsf_ package) as long as a simple numpy array is passed within the psf dictionary for each filter.\n",
    "\n",
    "We also enable automatic super sampling of the image via the `psf_resample_factor` argument to improve the results of the convolution. The number of pixels along an axis will be increased by this factor prior to the intial image creation, the convolution is then applied at the super resolution and then all images are downsampled back to the native resolution.\n",
    "\n",
    "Note that a single call to `Galaxy.make_image` computes all types of images needed depending on the passed arguments, there is no need to create the image without the PSF first as we did above. Using the lower level interface each stage can be applied separately (see the images docs). The initial \"PSF-less\" image will be created at the super sampled resolution and then both `Image.imgs` and the PSF convolved images will be downsampled after convolution to the native pixel resolution. For finer control over resampling the user can use the base Image objects themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee4b5382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a fake PSF for each filter\n",
    "psf = np.outer(     \n",
    "    signal.windows.gaussian(50, 3), signal.windows.gaussian(50, 3)\n",
    ")\n",
    "psfs = {f: psf for f in filters.filter_codes}\n",
    "\n",
    "img_start = time.time()\n",
    "\n",
    "# Get the image\n",
    "psf_img = gal.make_images(\n",
    "    resolution,\n",
    "    fov=width,\n",
    "    img_type=\"smoothed\",\n",
    "    sed=sed,\n",
    "    filters=filters,\n",
    "    rest_frame=False,\n",
    "    cosmo=cosmo,\n",
    "    psfs=psfs,\n",
    "    psf_resample_factor=2,\n",
    ")\n",
    "\n",
    "print(\"PSF images made, took:\", time.time() - img_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb121d1c",
   "metadata": {},
   "source": [
    "After convolution the results are stored in a dictionary, `Image.imgs_psf` (or `Image.img_psf` for singular images made from an array). Here we will use the plotting helper function to plot these images with some normalisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "847dac1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "psf_imgs = psf_img.imgs_psf\n",
    "\n",
    "# Lets set up a simple normalisation across all images\n",
    "vmax = 0\n",
    "for img in psf_imgs.values():\n",
    "    up = np.percentile(img, 99.9)\n",
    "    if up > vmax:\n",
    "        vmax = up\n",
    "    \n",
    "# Get the plot\n",
    "fig, ax = psf_img.plot_image(img_type=\"psf\", show=True, vmin=0, vmax=vmax)\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583c16ea",
   "metadata": {},
   "source": [
    "## Including noise\n",
    "\n",
    "The final ingredient for a fully forward modelled synthetic image is a noise field. We enable a couple interfaces to implement these on the images: \n",
    "- A simple implementation via the `noises` argument. If this argument is passed to `Galaxy.make_image` then a noise field will be created centred on 0 with this standard deviation for each filer if `noises` is a dictionary. If `noises` is a single value it will be used for all filters.\n",
    "- A more sophisticated method where the noise is calculated using an aperture, a signal to noise ratio/s (SNR/s), and depths in each filter. The arguments are defined as follows:\n",
    "    - `aperture`: Either a single value or a dicitonary with a value per filter defining the radius of the aperture in which the noise is defined. This/these values are assumed to be in the image unit system defined by the resolution.\n",
    "    - `snrs`: Either a single value or a dicitonary with a value per filter defining the signal to noise ratio inside the aperture.\n",
    "    - `depths`: Either a single value or a dicitonary with a value and unit per filter defining the depth in each filter. Must be defined in the same units as the pixel values (erg / s / Hz for rest frame luminosity, nJy for flux images). There are helper functions in `synthesizer.utils` which enable easy switching between unit systems. \n",
    "    \n",
    "As with the PSF images this can all be handled in a single call to `Galaxy.make_image`. If PSFs have been provided the noise will be applied to the images with a PSF, otherwise the PSF-less images will be used.\n",
    "\n",
    "Below we demonstrate the the first simple approach using the `noises` argument. Images with noise are stored in a dictionary, `Image.imgs_noise` (or `Image.img_noise` for singular images made from an array). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "396666e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redefine image resolution (here we arbitrarily set it to 50 pixels along an axis)\n",
    "resolution = (width.value / 50) * Mpc\n",
    "\n",
    "img_start = time.time()\n",
    "\n",
    "# Get the image\n",
    "simple_noise_img = gal.make_images(\n",
    "    resolution,\n",
    "    fov=width,\n",
    "    img_type=\"smoothed\",\n",
    "    sed=sed,\n",
    "    filters=filters,\n",
    "    rest_frame=False,\n",
    "    cosmo=cosmo,\n",
    "    psfs=psfs,\n",
    "    psf_resample_factor=2,\n",
    "    noises=100 * nJy,\n",
    ")\n",
    "\n",
    "print(\"Noisy images made, took:\", time.time() - img_start)\n",
    "\n",
    "simple_noise_imgs = simple_noise_img.imgs_noise\n",
    "\n",
    "# Lets set up a simple normalisation across all images\n",
    "vmax = 0\n",
    "for img in simple_noise_imgs.values():\n",
    "    up = np.percentile(img, 99.9)\n",
    "    if up > vmax:\n",
    "        vmax = up\n",
    "\n",
    "# Get the plot\n",
    "fig, ax = simple_noise_img.plot_image(img_type=\"noise\", show=True, vmin=0, vmax=vmax)\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7d7b47",
   "metadata": {},
   "source": [
    "And here we define a toy set of `depths` with a fixed SNR and aperture size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a25e8d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redefine image resolution (here we arbitrarily set it to 50 pixels along an axis)\n",
    "resolution = (width.value / 50) * Mpc\n",
    "\n",
    "# Create the dictionary of depths\n",
    "depths = {f.filter_code: 2000 * nJy for f in filters}\n",
    "\n",
    "img_start = time.time()\n",
    "\n",
    "# Get the image\n",
    "noise_img = gal.make_images(\n",
    "    resolution,\n",
    "    fov=width,\n",
    "    img_type=\"smoothed\",\n",
    "    sed=sed,\n",
    "    filters=filters,\n",
    "    rest_frame=False,\n",
    "    cosmo=cosmo,\n",
    "    psfs=psfs,\n",
    "    psf_resample_factor=2,\n",
    "    depths=depths,\n",
    "    snrs=5,\n",
    "    aperture=0.2,\n",
    ")\n",
    "\n",
    "print(\"Smoothed images made, took:\", time.time() - img_start)\n",
    "\n",
    "noise_imgs = noise_img.imgs_noise\n",
    "print([noise_imgs[f.filter_code].shape for f in filters])\n",
    "# Lets set up a simple normalisation across all images\n",
    "vmax = 0\n",
    "vmin = np.inf\n",
    "for img in noise_imgs.values():\n",
    "    up = np.percentile(img, 99.9)\n",
    "    low = -np.percentile(img, 32)\n",
    "    if up > vmax:\n",
    "        vmax = up\n",
    "    if low < vmin:\n",
    "        vmin = low\n",
    "        \n",
    "# Get the plot\n",
    "fig, ax = simple_noise_img.plot_image(img_type=\"noise\", show=True, vmin=vmin, vmax=vmax)\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5598bc9a",
   "metadata": {},
   "source": [
    "Finally we can use the RGB image method on the `Image` object to make quick RGB images by simply providing a dictionary detailing which filters we want in which bands, the type of image we want (once again `\"standard\"`, `\"psf\"`, or `\"noise\"`) and optional weights which we will ignore here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f560d311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the rgb image from the psf image above example using our 3 filters\n",
    "rgb_img = noise_img.make_rgb_image(\n",
    "    rgb_filters={\"R\": [\"JWST/NIRCam.F200W\",],\n",
    "                 \"G\": [\"JWST/NIRCam.F150W\",],\n",
    "                 \"B\": [\"JWST/NIRCam.F090W\",]},\n",
    "    img_type=\"noise\",\n",
    ")\n",
    "\n",
    "# Set up minima and maxima\n",
    "vmin = -np.percentile(rgb_img, 32)\n",
    "vmax = np.percentile(rgb_img, 99.9)\n",
    "norm = cm.Normalize(vmin=vmin, vmax=vmax, clip=True)\n",
    "print(\"Scaling to:\", vmin, \"->\", vmax)\n",
    "\n",
    "# Normalise the image.\n",
    "rgb_img = norm(rgb_img)\n",
    "\n",
    "print(rgb_img.shape)\n",
    "\n",
    "# Plot the image\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.imshow(rgb_img, origin=\"lower\", interpolation=\"nearest\")\n",
    "ax.axis(\"off\")\n",
    "plt.show()\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e95a5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318af4b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
